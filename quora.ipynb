{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize as wt \n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qs= pd.read_csv('questions.csv',header=0)\n",
    "new_qs_df = df_qs.sample(100000)\n",
    "new_qs_df.drop(['id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    words = wt(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stopWords]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_qs_df['question1']=new_qs_df['question1'].apply(lambda x: str(x).replace('.', '').replace(',', '').replace(\"'\", '').replace('\"', '').replace('-',' ').replace('&','and').replace('?',''))\n",
    "new_qs_df['question2']=new_qs_df['question2'].apply(lambda x: str(x).replace('.', '').replace(',', '').replace(\"'\", '').replace('\"', '').replace('-',' ').replace('&','and').replace('?',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_qs_df['question1']=new_qs_df['question1'].apply(lambda x:remove_stopwords(x))\n",
    "new_qs_df['question2']=new_qs_df['question2'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15347</th>\n",
       "      <td>30634</td>\n",
       "      <td>30635</td>\n",
       "      <td>people QUORA ask questions easily findout Google</td>\n",
       "      <td>dont Quora people look answer Google</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112052</th>\n",
       "      <td>222174</td>\n",
       "      <td>222175</td>\n",
       "      <td>time travel anyhow</td>\n",
       "      <td>time travel possible next 10 years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169380</th>\n",
       "      <td>334723</td>\n",
       "      <td>334724</td>\n",
       "      <td>requirements become President United States re...</td>\n",
       "      <td>requirements become president United States re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165951</th>\n",
       "      <td>328009</td>\n",
       "      <td>328010</td>\n",
       "      <td>copilotsearchcom</td>\n",
       "      <td>Yellowlegcom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392998</th>\n",
       "      <td>768078</td>\n",
       "      <td>768079</td>\n",
       "      <td>future mental health treatment</td>\n",
       "      <td>ways mental health professions change next 20 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          qid1    qid2                                          question1  \\\n",
       "15347    30634   30635   people QUORA ask questions easily findout Google   \n",
       "112052  222174  222175                                 time travel anyhow   \n",
       "169380  334723  334724  requirements become President United States re...   \n",
       "165951  328009  328010                                   copilotsearchcom   \n",
       "392998  768078  768079                     future mental health treatment   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "15347                dont Quora people look answer Google             1  \n",
       "112052                 time travel possible next 10 years             1  \n",
       "169380  requirements become president United States re...             0  \n",
       "165951                                       Yellowlegcom             0  \n",
       "392998  ways mental health professions change next 20 ...             1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_qs_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>feature engineering</h1>\n",
    "<h3>New Features</h3>\n",
    "<li>total characters ✅</li>\n",
    "<li>total words ✅</li>\n",
    "<li>Common word count ✅</li>\n",
    "<li>sentence character Length difference ✅ </li>\n",
    "<li>difference in number of words ✅</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_characters(text):\n",
    "    return len(text)\n",
    "def total_words(text):\n",
    "    return len(text.split())\n",
    "def common_words(text):\n",
    "    return len(set(text['question1'].split()) & set(text['question2'].split()))\n",
    "def chara_len_diff(text):\n",
    "    return abs(len(''.join(wt(text['question1'])))-len(''.join(wt(text['question2']))))\n",
    "def total_word_count_diff(text):\n",
    "    return abs(len(wt(text['question1']))-len(wt(text['question2'])))\n",
    "# print(common_words(new_qs_df[243945]))\n",
    "# print(total_words(new_qs_df['question1'][152007]),' ',total_words(new_qs_df['question2'][152007]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=new_qs_df.sample(5)\n",
    "# x['word diff cnt']=x.apply(lambda x:total_word_count_diff(x),axis=1)\n",
    "# x[['question1','question2','word diff cnt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_qs_df['question1']=new_qs_df['question1'].str.lower()\n",
    "new_qs_df['question2']=new_qs_df['question2'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_qs_df['total_characters_q1']=new_qs_df['question1'].apply(lambda x:total_characters(x))\n",
    "new_qs_df['total_characters_q2']=new_qs_df['question2'].apply(lambda x:total_characters(x))\n",
    "new_qs_df['total_words_q1']=new_qs_df['question1'].apply(lambda x:total_words(x))\n",
    "new_qs_df['total_words_q2']=new_qs_df['question2'].apply(lambda x:total_words(x))\n",
    "new_qs_df['total_common_words']=new_qs_df.apply(lambda x:common_words(x),axis=1)\n",
    "new_qs_df['chara_len_diff']=new_qs_df.apply(lambda x:chara_len_diff(x),axis=1)\n",
    "new_qs_df['word_diff_count']=new_qs_df.apply(lambda x:total_word_count_diff(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>total_characters_q1</th>\n",
       "      <th>total_characters_q2</th>\n",
       "      <th>total_words_q1</th>\n",
       "      <th>total_words_q2</th>\n",
       "      <th>total_common_words</th>\n",
       "      <th>chara_len_diff</th>\n",
       "      <th>word_diff_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15347</th>\n",
       "      <td>30634</td>\n",
       "      <td>30635</td>\n",
       "      <td>people quora ask questions easily findout google</td>\n",
       "      <td>dont quora people look answer google</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112052</th>\n",
       "      <td>222174</td>\n",
       "      <td>222175</td>\n",
       "      <td>time travel anyhow</td>\n",
       "      <td>time travel possible next 10 years</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169380</th>\n",
       "      <td>334723</td>\n",
       "      <td>334724</td>\n",
       "      <td>requirements become president united states re...</td>\n",
       "      <td>requirements become president united states re...</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165951</th>\n",
       "      <td>328009</td>\n",
       "      <td>328010</td>\n",
       "      <td>copilotsearchcom</td>\n",
       "      <td>yellowlegcom</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392998</th>\n",
       "      <td>768078</td>\n",
       "      <td>768079</td>\n",
       "      <td>future mental health treatment</td>\n",
       "      <td>ways mental health professions change next 20 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222812</th>\n",
       "      <td>439173</td>\n",
       "      <td>439174</td>\n",
       "      <td>get list gmail accounts phone march 2015</td>\n",
       "      <td>get list gmail account phone march 2015</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35732</th>\n",
       "      <td>71197</td>\n",
       "      <td>71198</td>\n",
       "      <td>china help nepal</td>\n",
       "      <td>help nepal</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109585</th>\n",
       "      <td>217309</td>\n",
       "      <td>217310</td>\n",
       "      <td>cold gobi desert get average temperatures comp...</td>\n",
       "      <td>cold gobi desert get average temperatures comp...</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>73</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312023</th>\n",
       "      <td>612460</td>\n",
       "      <td>612461</td>\n",
       "      <td>families inter religion marriage failed convin...</td>\n",
       "      <td>done families inter religion marriage failed c...</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285274</th>\n",
       "      <td>560663</td>\n",
       "      <td>560664</td>\n",
       "      <td>increase website traffic</td>\n",
       "      <td>increase traffic website without investing</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          qid1    qid2                                          question1  \\\n",
       "15347    30634   30635   people quora ask questions easily findout google   \n",
       "112052  222174  222175                                 time travel anyhow   \n",
       "169380  334723  334724  requirements become president united states re...   \n",
       "165951  328009  328010                                   copilotsearchcom   \n",
       "392998  768078  768079                     future mental health treatment   \n",
       "...        ...     ...                                                ...   \n",
       "222812  439173  439174           get list gmail accounts phone march 2015   \n",
       "35732    71197   71198                                   china help nepal   \n",
       "109585  217309  217310  cold gobi desert get average temperatures comp...   \n",
       "312023  612460  612461  families inter religion marriage failed convin...   \n",
       "285274  560663  560664                           increase website traffic   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "15347                dont quora people look answer google             1   \n",
       "112052                 time travel possible next 10 years             1   \n",
       "169380  requirements become president united states re...             0   \n",
       "165951                                       yellowlegcom             0   \n",
       "392998  ways mental health professions change next 20 ...             1   \n",
       "...                                                   ...           ...   \n",
       "222812            get list gmail account phone march 2015             1   \n",
       "35732                                          help nepal             0   \n",
       "109585  cold gobi desert get average temperatures comp...             1   \n",
       "312023  done families inter religion marriage failed c...             1   \n",
       "285274         increase traffic website without investing             1   \n",
       "\n",
       "        total_characters_q1  total_characters_q2  total_words_q1  \\\n",
       "15347                    48                   36               7   \n",
       "112052                   18                   34               3   \n",
       "169380                   73                   78               8   \n",
       "165951                   16                   12               1   \n",
       "392998                   30                   51               4   \n",
       "...                     ...                  ...             ...   \n",
       "222812                   40                   39               7   \n",
       "35732                    16                   10               3   \n",
       "109585                   68                   73              10   \n",
       "312023                   57                   62               7   \n",
       "285274                   24                   42               3   \n",
       "\n",
       "        total_words_q2  total_common_words  chara_len_diff  word_diff_count  \n",
       "15347                6                   3              11                1  \n",
       "112052               6                   2              13                3  \n",
       "169380               8                   6               5                0  \n",
       "165951               1                   0               4                0  \n",
       "392998               8                   2              17                4  \n",
       "...                ...                 ...             ...              ...  \n",
       "222812               7                   6               1                0  \n",
       "35732                2                   2               5                1  \n",
       "109585              11                   8               4                1  \n",
       "312023               8                   6               4                1  \n",
       "285274               5                   3              16                2  \n",
       "\n",
       "[100000 rows x 12 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_qs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(text):\n",
    "    lemm = [word.lemma_ for word in nlp(text)]\n",
    "    return ' '.join(lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_qs_df['question1']=new_qs_df['question1'].apply(lambda x:lemma(x))\n",
    "new_qs_df['question2']=new_qs_df['question2'].apply(lambda x:lemma(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_qs_df['question1']=new_qs_df['question1'].apply(lambda x: wt(x))\n",
    "# new_qs_df['question2']=new_qs_df['question2'].apply(lambda x: wt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques=list(new_qs_df['question1'])+list(new_qs_df['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=3000)\n",
    "q1_ar,q2_ar = np.vsplit(cv.fit_transform(ques).toarray(),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf1=pd.DataFrame(q1_ar,index=new_qs_df.index)\n",
    "tdf2=pd.DataFrame(q2_ar,index=new_qs_df.index)\n",
    "tdf = pd.concat([tdf1,tdf2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = new_qs_df.drop(columns=['qid1','qid2','question1','question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6008)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df=pd.concat([final_df, tdf], axis=1)\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(final_df.iloc[:,1:].values,final_df.iloc[:,0].values,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7828333333333334"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7661"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Quora_rfmodel.pkl', 'wb') as f:\n",
    "    pickle.dump(rf, f)\n",
    "with open('Quora_XGBmodel.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
